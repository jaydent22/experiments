{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and labels\n",
    "data = pd.read_pickle('pifsc_embeddings2.pickle')\n",
    "features = dict(data)\n",
    "data = pd.read_pickle('pifsc_embeddings.pkl')\n",
    "features.update(data)\n",
    "\n",
    "cols = [\"species\",\"image\",\"distinctiveness\",\"quality\"]\n",
    "labels1 = pd.read_csv('pifsc_labels_detail.csv')[cols]\n",
    "labels1[['quality', 'distinctiveness']] = labels1[['distinctiveness', 'quality']]\n",
    "\n",
    "cols = [\"species\",\"filename\",\"distinctiveness\",\"quality\"]\n",
    "labels2 = pd.read_csv('pifsc_labels2.csv')[cols]\n",
    "labels2.columns = [\"species\",\"image\",\"distinctiveness\",\"quality\"]\n",
    "\n",
    "labels = pd.concat([labels1, labels2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean labels\n",
    "is_na = labels.quality.isna()\n",
    "labels = labels.loc[~is_na]\n",
    "labels = labels.drop_duplicates(subset='image', keep='first')\n",
    "# labels.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# clean features\n",
    "imgs = labels.image.tolist()\n",
    "features = {k: v for k, v in features.items() if k in imgs}\n",
    "assert len(features) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data, split\n",
    "Y = labels.quality\n",
    "X = np.array([features[i] for i in labels.image])\n",
    "species_code = labels.species.astype('category').cat.codes\n",
    "X = np.insert(X, 0, species_code, axis=1)\n",
    "target_names = 'high medium low'.split()\n",
    "# species = labels.species.astype('category').cat.codes\n",
    "# X = np.insert(X, 0, species, axis=1)\n",
    "# sc = StandardScaler()\n",
    "# X = sc.fit_transform(X)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP\n",
    "model = MLPClassifier(max_iter=300, random_state=42, early_stopping=True)\n",
    "# train Logistic regression\n",
    "# classifiers = [SVC(class_weight='balanced', random_state=42, kernel='poly', degree=2),\n",
    "#                SVC(class_weight='balanced', random_state=42, kernel='poly')]\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150), (100, 50)],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "n_iter = 20\n",
    "random_search = RandomizedSearchCV(model, params, n_iter=n_iter, n_jobs=-1, cv=5, random_state=42, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     16\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X, Y)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomizedSearchCV took \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m seconds for \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m candidates parameter settings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;241m%\u001b[39m ((time() \u001b[38;5;241m-\u001b[39m start), n_iter)\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m report(random_search\u001b[38;5;241m.\u001b[39mcv_results_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "t0 = time()\n",
    "random_search.fit(X, Y)\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - t0), n_iter)\n",
    ")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.2s remaining:   13.7s\n"
     ]
    }
   ],
   "source": [
    "best = random_search.best_estimator_\n",
    "pred = cross_val_predict(best, X, Y, n_jobs=-1, verbose=1)\n",
    "# print(f'deg={clf.degree}'.center(53, '-'))\n",
    "print(classification_report(Y, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "cm = confusion_matrix(Y, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot()\n",
    "# ax.title.set_text(f'{type(clf).__name__} {clf.kernel} {clf.degree}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
